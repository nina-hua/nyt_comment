{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments File\n",
    "comments = 'Data/combined_comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in File\n",
    "comm = pd.read_csv(comments).drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['commentType', 'commentBody', 'sectionName'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column \"userTitle\" has both NaN and string data types. Replace Nan with \"Unknown\" to have one uniform data type in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentType</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>sectionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>The snake-filled heads comment made me think o...</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>She-devil reporting for duty!</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>XX is the new mark of the devil.</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment</td>\n",
       "      <td>\"Courtland Sykes\" should be writing for The On...</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>I happen to descend for a few of them, because...</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  commentType                                        commentBody sectionName\n",
       "0     comment  The snake-filled heads comment made me think o...     Unknown\n",
       "1     comment                      She-devil reporting for duty!     Unknown\n",
       "2     comment                   XX is the new mark of the devil.     Unknown\n",
       "3     comment  \"Courtland Sykes\" should be writing for The On...     Unknown\n",
       "4     comment  I happen to descend for a few of them, because...     Unknown"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unknown', 'Politics', 'Television', 'Europe', 'Middle East',\n",
       "       'Pro Football', 'Asia Pacific', 'Live', 'The Daily', 'Mind',\n",
       "       'Art & Design', 'Wine, Beer & Cocktails', 'Americas',\n",
       "       'Sunday Review', 'Economy', 'Family', 'Dance', 'Africa',\n",
       "       'Energy & Environment ', 'DealBook', 'Book Review', 'Music',\n",
       "       'Olympics', 'Move', 'Lesson Plans', 'Entrepreneurship', 'Baseball',\n",
       "       'Media', 'Entertainment', 'Opinion | Politics', 'Weddings',\n",
       "       'Real Estate', 'Eat', 'College Basketball', 'Australia',\n",
       "       'Retirement', 'Neighborhoods', 'Personal Tech', 'Canada', 'Hockey',\n",
       "       'Tennis', 'Cycling', 'Pro Basketball', 'Learning', 'Golf',\n",
       "       'Soccer', \"401(k)'s and Similar Plans\", 'Rugby',\n",
       "       'College Football', 'Paying for College', 'Insider Events',\n",
       "       'Editorials', 'Fashion & Beauty', 'World Cup', nan, 'Automobiles',\n",
       "       'Food', 'Art', 'Opinion | The World', 'Cricket', 'Room For Debate',\n",
       "       'Education Life', 'Student Loans', 'Auto Racing'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm.sectionName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (comm.sectionName != \"Unknown\") & (comm.commentType == \"comment\") & comm.sectionName.notna()\n",
    "data = comm.commentBody[filt]\n",
    "sections = comm.sectionName[filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_target, test_target = train_test_split(data, sections, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(decode_error='ignore',\n",
    "                             stop_words='english')\n",
    "lsvc_model = Pipeline([('vec', vectorizer),\n",
    "                       ('clf', LinearSVC(random_state=RANDOM_STATE))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        s... max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=28, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_model.fit(train_data, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Metric Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6897999957790175"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_model.score(test_data, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With TdidfVectorizor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(input='content',\n",
    "                            analyzer='word',\n",
    "                            stop_words='english',\n",
    "                            decode_error='ignore')\n",
    "\n",
    "lsvc_model = Pipeline([('vec', vectorizer),\n",
    "                       ('clf', LinearSVC(random_state=RANDOM_STATE))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "   ... max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=28, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_model.fit(train_data, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7234060514819166"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_model.score(test_data, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(input='content',\n",
    "                            analyzer='word',\n",
    "                            stop_words='english',\n",
    "                            decode_error='ignore',\n",
    "                            ngram_range=(1, 2))\n",
    "\n",
    "lsvc_model = Pipeline([('vec', vectorizer),\n",
    "                       ('clf', LinearSVC(loss='squared_hinge', random_state=RANDOM_STATE))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "   ... max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=28, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_model.fit(train_data, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7364559223902017"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_model.score(test_data, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Model with Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7364559223902017\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "401(k)'s and Similar Plans       1.00      0.25      0.40        12\n",
      "                    Africa       0.72      0.26      0.38       244\n",
      "                  Americas       0.74      0.31      0.44      1267\n",
      "                       Art       0.00      0.00      0.00        13\n",
      "              Art & Design       0.86      0.64      0.73       860\n",
      "              Asia Pacific       0.66      0.46      0.54      4510\n",
      "                 Australia       0.75      0.17      0.28        89\n",
      "               Auto Racing       1.00      0.71      0.83        17\n",
      "               Automobiles       1.00      0.11      0.20         9\n",
      "                  Baseball       0.87      0.78      0.82       562\n",
      "               Book Review       0.74      0.16      0.26       459\n",
      "                    Canada       0.78      0.36      0.50       373\n",
      "        College Basketball       0.80      0.54      0.65       174\n",
      "          College Football       0.97      0.38      0.55        95\n",
      "                   Cycling       0.94      0.46      0.62        35\n",
      "                     Dance       0.91      0.49      0.63        41\n",
      "                  DealBook       0.72      0.32      0.44       846\n",
      "                       Eat       0.68      0.52      0.59       639\n",
      "                   Economy       0.58      0.29      0.38      1829\n",
      "                Editorials       0.75      0.06      0.11       198\n",
      "            Education Life       0.91      0.30      0.45       285\n",
      "     Energy & Environment        0.63      0.34      0.45       297\n",
      "             Entertainment       0.00      0.00      0.00         1\n",
      "          Entrepreneurship       0.50      0.25      0.33         4\n",
      "                    Europe       0.66      0.39      0.49      7625\n",
      "                    Family       0.68      0.58      0.62      2514\n",
      "          Fashion & Beauty       0.00      0.00      0.00         1\n",
      "                      Food       0.00      0.00      0.00         3\n",
      "                      Golf       0.89      0.50      0.64        80\n",
      "                    Hockey       0.81      0.42      0.55        60\n",
      "            Insider Events       0.00      0.00      0.00         2\n",
      "                  Learning       1.00      0.10      0.18        20\n",
      "              Lesson Plans       1.00      0.09      0.16        34\n",
      "                      Live       0.69      0.58      0.63      1584\n",
      "                     Media       0.79      0.47      0.59      3269\n",
      "               Middle East       0.70      0.54      0.61      5133\n",
      "                      Mind       0.75      0.33      0.46       305\n",
      "                      Move       0.76      0.64      0.70       974\n",
      "                     Music       0.88      0.57      0.69       450\n",
      "             Neighborhoods       0.00      0.00      0.00         8\n",
      "                  Olympics       0.80      0.55      0.65       535\n",
      "        Opinion | Politics       0.87      0.41      0.56       164\n",
      "        Paying for College       1.00      0.07      0.13        14\n",
      "             Personal Tech       0.63      0.10      0.17       124\n",
      "                  Politics       0.77      0.92      0.83     77733\n",
      "            Pro Basketball       0.92      0.66      0.77       152\n",
      "              Pro Football       0.80      0.60      0.68       371\n",
      "               Real Estate       0.00      0.00      0.00         1\n",
      "                Retirement       1.00      0.08      0.14        78\n",
      "           Room For Debate       0.74      0.33      0.46       185\n",
      "                     Rugby       0.92      0.46      0.61        24\n",
      "                    Soccer       0.86      0.54      0.66       185\n",
      "             Student Loans       0.62      0.18      0.28        45\n",
      "             Sunday Review       0.64      0.60      0.62     24948\n",
      "                Television       0.86      0.69      0.76      2335\n",
      "                    Tennis       0.85      0.57      0.68       111\n",
      "                 The Daily       0.00      0.00      0.00        37\n",
      "                  Weddings       0.50      0.04      0.08        24\n",
      "    Wine, Beer & Cocktails       0.86      0.68      0.76       157\n",
      "                 World Cup       0.00      0.00      0.00         3\n",
      "\n",
      "               avg / total       0.73      0.74      0.72    142147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vietpride12/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predictions = lsvc_model.predict(test_data)\n",
    "print(accuracy_score(test_target, predictions))\n",
    "print(classification_report(test_target, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Models/svm_full.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(lsvc_model, 'Models/svm_full.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump_session('Notebook_Saves/LinearSVM_Total_Data.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
